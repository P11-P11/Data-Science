{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8mU_b85RLsd",
        "outputId": "7d5d5513-7ca1-4817-9d16-269fd7551ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Van a recibir dos archivos con datos: train.csv y test4alumnxs.csv, los cuales contienen información sobre accidentes de tránsito en EEUU (más información abajo). La diferencia entre los archivos es que train.csv tiene la columna 'Severity' (severidad) mientras que test4alumnxs.csv no la tiene.\n",
        "\n",
        "2.   El objetivo es usar los datos para construir un modelo que prediga la severidad del accidente (columna 'Severity', donde 0 es baja severidad y 1 es alta severidad). Para esto, primero pueden usar los datos del archivo train.csv para ajustar los parámetros de su modelo, ajustar los hiperparámetros, combinar los features para agregar nuevos, estandarizar los datos, etc. Al terminar esto, tienen un modelo entrenado en estos datos, y una idea de que tan bien funciona.\n",
        "\n",
        "\n",
        "3.   Luego, aplican ese modelo a los datos de test4alumnxs.csv y generan un vector de probabilidades que representan la probabilidad de que cada accidente sea severo.\n",
        "\n",
        "4.   Nosotros tenemos acceso a las etiquetas, así que podemos calcular el AUC de sus predicciones. Con eso construimos un ranking de los mejores clasificadores."
      ],
      "metadata": {
        "id": "3KRurITxKKgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los datos corresponden a registros de accidentes de tránsito en EEUU entre 2016 y 2021.\n",
        "\n",
        "Las primeras dos columnas (\"unnamed\") no sirve nara nada y se pueden descartar.\n",
        "\n",
        "La columna 'Severity' contiene la severidad del accidente (0 significa baja, 1 significa alta)\n",
        "\n",
        "Luego tenemos la hora de comienzo y final del accidente, la latitud/longitud inicial y final del accidente (entre que valores queda delimitado), la distancia de camino afectada por el accidente, una descripción verbal hecha por un humano, número y nombre de la calle donde ocurrió, lado de la calle (izquierda o derecha), ciudad, condado, estado, código postal, huso horario, código de aeropuerto donde se encuentra la estación meterológica más cercana al accidente, hora en la cual se midió el clima,temperatura, temperatura del viento, humedad, presión, visibilidad, dirección del viento, condición climática (despejado, sol, nieve, etc), presencia de comodidades (\"amenities\") en la cercanía del accidente, presencia de loma de burro, presencia de un cruce, presencia de señal de ceder paso, presencia de unión de calles, presencia de cartel de no salida, presencia de vías de tren, presencia de rotonda, presencia de estación, presencia de signo de parar, presencia de moderadores de tráfico, presencia de señales de tránsito, presencia de calle en forma de U (\"loop\"), día u oscuridad de acuerdo a la salida del sol, día u oscuridad de acuerdo a la penumbra civil (si es o no necesario utilizar alumbramiento eléctrico), día u oscuridad de acuerdo a la penumbra náutica, día u oscuridad de acuerdo a la penumbra astronómica.\n",
        "\n",
        "No todos estos campos son necesariamente útiles, y tampoco no todos están en un formato numérico directamente utilizable (por ejemplo, hay strings en la parte de descripción del accidente). Es parte del trabajo decidir que features quedarse, que features sumar, y como extraer información relevante de los features más complejos."
      ],
      "metadata": {
        "id": "VUmceUuXKRYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/P11-P11/Data-Science.git\n",
        "\n",
        "%cd Data-Science\n",
        "\n",
        "!git checkout Clasification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-TcU-lbKdCD",
        "outputId": "4f030632-721d-4ca8-f62b-6f06238e1bbc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Data-Science'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18/18), 7.01 MiB | 5.00 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_folder_path = 'Data'\n",
        "files_in_data_folder = os.listdir(data_folder_path)\n",
        "\n",
        "# Imprimir los nombres de los archivos\n",
        "for file_name in files_in_data_folder:\n",
        "    print(file_name)\n",
        "\n",
        "dataframes = []\n",
        "\n",
        "for file_name in os.listdir(data_folder_path):\n",
        "    file_path = os.path.join(data_folder_path, file_name)\n",
        "\n",
        "    if file_name.endswith('.csv'):\n",
        "        df = pd.read_csv(file_path)\n",
        "        dataframes.append(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-5sKuT-Kzg4",
        "outputId": "2112e356-a5c8-49cd-f263-0bd5979e1d64"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.csv\n",
            "test4alumnxs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = dataframes[0]\n",
        "df_test = dataframes[1]"
      ],
      "metadata": {
        "id": "oxPjvc0XMAhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SEVEROS\n",
        "def rutaCerrada(x):\n",
        "  if 'Road closed' in x:\n",
        "    return 1\n",
        "  else: return 0\n",
        "def carrilesCerrados(x):\n",
        "  if 'All lanes closed' in x:\n",
        "    return 1\n",
        "  else: return 0\n",
        "#NO SEVEROS\n",
        "def estadoSeguro(x):\n",
        "  if x == 'CA' or x == 'FL':\n",
        "    return 1\n",
        "  else: return 0\n",
        "def driveCaution(x):\n",
        "  if 'Drive with caution' in x:\n",
        "    return 1\n",
        "  else: return 0\n",
        "def traficoEstacionario(x):\n",
        "  if 'Stationary traffic' in x:\n",
        "    return 1\n",
        "  else: return 0\n",
        "def traficoLento(x):\n",
        "  if 'Slow traffic' in x:\n",
        "    return 1\n",
        "  else: return 0\n",
        "\n"
      ],
      "metadata": {
        "id": "yTnjKBHARSB8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df_train[['Description','State','Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
        "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
        "       'Precipitation(in)', 'Weather_Condition','Bump', 'Crossing','Junction','Railway','Roundabout','Stop','Turning_Loop','Sunrise_Sunset']]\n",
        "#df['diaDeSemana'] = df[]\n",
        "df['estadoSeguro'] = df['State'].apply(estadoSeguro)\n",
        "df['driveCaution'] = df['Description'].apply(driveCaution)\n",
        "df['traficoEstacionario'] = df['Description'].apply(traficoEstacionario)\n",
        "df['traficoLento'] = df['Description'].apply(traficoLento)\n",
        "df['rutaCerrada'] = df['Description'].apply(rutaCerrada)\n",
        "df['carrilesCerrados'] = df['Description'].apply(carrilesCerrados)\n"
      ],
      "metadata": {
        "id": "j6fAl8G_RUaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(df_train['Severity']) # armo el vector de etiquetas\n",
        "# extraigo la matriz de features X\n",
        "features = ['Temperature(F)', 'Wind_Chill(F)',\n",
        "       'Humidity(%)', 'Pressure(in)', 'Visibility(mi)',\n",
        "       'Wind_Speed(mph)', 'Precipitation(in)',  'Bump',\n",
        "       'Crossing', 'Junction', 'Railway', 'Roundabout', 'Stop', 'Turning_Loop',\n",
        "       'estadoSeguro', 'driveCaution', 'traficoEstacionario',\n",
        "       'traficoLento', 'rutaCerrada', 'carrilesCerrados']\n",
        "X = np.array(df[features])\n"
      ],
      "metadata": {
        "id": "K5LdWYrcRW5L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
        "\n",
        "\n",
        "\n",
        "# pruebo con un random forest así como viene de fábrica\n",
        "clf = RandomForestClassifier(1000)\n",
        "\n",
        "# ajusto el modelo\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# armo el vector de predicciones.\n",
        "# lo que tengo entregar\n",
        "y_hat_test = clf.predict_proba(X_test)[:, 1]\n",
        "y_hat_train = clf.predict_proba(X_train)[:, 1]\n",
        "\n",
        "# evaluo el AUC\n",
        "roc_test = roc_auc_score(y_test, y_hat_test)\n",
        "roc_train = roc_auc_score(y_train, y_hat_train)\n",
        "roc_test, roc_train\n"
      ],
      "metadata": {
        "id": "a_vlgAHGR_ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c9d904-c6c5-45bd-8f6c-e9d86dd4766e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9750880038600959, 0.9999757869110867)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}